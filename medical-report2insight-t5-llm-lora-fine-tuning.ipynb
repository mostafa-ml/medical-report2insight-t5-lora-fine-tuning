{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Medical Insight Extraction from Clinical Reports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T13:52:31.224391Z",
                    "iopub.status.busy": "2025-05-11T13:52:31.223479Z",
                    "iopub.status.idle": "2025-05-11T13:52:31.228113Z",
                    "shell.execute_reply": "2025-05-11T13:52:31.227408Z",
                    "shell.execute_reply.started": "2025-05-11T13:52:31.224360Z"
                },
                "executionInfo": {
                    "elapsed": 3,
                    "status": "ok",
                    "timestamp": 1746003496131,
                    "user": {
                        "displayName": "Mostafa Essam",
                        "userId": "04610803808530795661"
                    },
                    "user_tz": -180
                },
                "id": "Wpi0_V-9cDDL",
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# !pip install -q datasets\n",
                "# !pip install -q evaluate\n",
                "# !pip install -q rouge_score"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T13:55:52.760330Z",
                    "iopub.status.busy": "2025-05-11T13:55:52.759606Z",
                    "iopub.status.idle": "2025-05-11T13:55:52.764704Z",
                    "shell.execute_reply": "2025-05-11T13:55:52.764135Z",
                    "shell.execute_reply.started": "2025-05-11T13:55:52.760304Z"
                },
                "executionInfo": {
                    "elapsed": 6948,
                    "status": "ok",
                    "timestamp": 1746003496116,
                    "user": {
                        "displayName": "Mostafa Essam",
                        "userId": "04610803808530795661"
                    },
                    "user_tz": -180
                },
                "id": "usvBYef1c8s8",
                "trusted": true
            },
            "outputs": [],
            "source": [
                "from datasets import load_dataset\n",
                "import textwrap\n",
                "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
                "from peft import LoraConfig, TaskType, get_peft_model, PeftModel\n",
                "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
                "import torch\n",
                "from torch.utils.data import DataLoader\n",
                "from tqdm import tqdm\n",
                "import evaluate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T14:00:47.187258Z",
                    "iopub.status.busy": "2025-05-11T14:00:47.186536Z",
                    "iopub.status.idle": "2025-05-11T14:00:47.350012Z",
                    "shell.execute_reply": "2025-05-11T14:00:47.349387Z",
                    "shell.execute_reply.started": "2025-05-11T14:00:47.187233Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "from kaggle_secrets import UserSecretsClient\n",
                "user_secrets = UserSecretsClient()\n",
                "WANDB_API_KEY = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
                "HF_API_KEY = user_secrets.get_secret(\"HF_API_KEY\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T13:57:57.009883Z",
                    "iopub.status.busy": "2025-05-11T13:57:57.009147Z",
                    "iopub.status.idle": "2025-05-11T13:58:04.772548Z",
                    "shell.execute_reply": "2025-05-11T13:58:04.771828Z",
                    "shell.execute_reply.started": "2025-05-11T13:57:57.009850Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
                        "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
                        "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
                        "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmk-mostafaessam\u001b[0m (\u001b[33mmk-mostafaessam-helwan-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import wandb\n",
                "\n",
                "# https://wandb.ai/authorize\n",
                "wandb.login(key=WANDB_API_KEY)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T14:01:19.330662Z",
                    "iopub.status.busy": "2025-05-11T14:01:19.330011Z",
                    "iopub.status.idle": "2025-05-11T14:01:19.333954Z",
                    "shell.execute_reply": "2025-05-11T14:01:19.333182Z",
                    "shell.execute_reply.started": "2025-05-11T14:01:19.330639Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# HF_API_KEY"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T14:01:27.718559Z",
                    "iopub.status.busy": "2025-05-11T14:01:27.718065Z",
                    "iopub.status.idle": "2025-05-11T14:01:27.738304Z",
                    "shell.execute_reply": "2025-05-11T14:01:27.737437Z",
                    "shell.execute_reply.started": "2025-05-11T14:01:27.718538Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "de6f4a8daccd4c3da44774aa832900fb",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "from huggingface_hub import notebook_login\n",
                "\n",
                "notebook_login()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "SCyMb4dc1K_F"
            },
            "source": [
                "# Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 241,
                    "referenced_widgets": [
                        "be3c9c403ae5455eb44b8c32763ddf6d",
                        "ce4afe04f30b4fd3bce3ca43ff168c0a",
                        "a4ab7d1762a748ab8948573f38276fb1",
                        "cdf34cb81391433fa86c44ff73594851",
                        "0c899600bb44436fb1a015a922802712",
                        "6ef7b9d1a8454f6e8d7e8caa2182c153",
                        "7829895c49b6445e8329c649edff7744",
                        "f8e1ba208dee4fd4999752ca4d1c7ab4",
                        "e45332d0ec0642df80c984fca9c111ce",
                        "e857ddbdaf5547469acc8dfff9a558a0",
                        "c52e6213eb1f4c1786a7633ac13c5a6b",
                        "c48f004a99e046ee8f8c909a2bf66b6e",
                        "7c7602fd2d9842168e1f193e0d616ec1",
                        "60c136df9cc94a3bbc67aa8402fd2095",
                        "d89e58f489ff46cfbcdc22fecab5c75b",
                        "da4350f5df0244c6a2c3ff49a73b5cd6",
                        "1fe32e31d80d4f56836ed47f384d8bfb",
                        "5fc1ae84f3c94ee998f9466951e99ef7",
                        "31fa09c869484096a6892985554e2b56",
                        "052e9e25b9d941acb7ecb06b6b7336e0",
                        "c3f94fcc67c840f78f1e17a75387bb39",
                        "534a93242dbf4f17a376efa6ceaf34e1",
                        "44c2ab4af9c34d1a9ea4a5d37f07339a",
                        "83d3066ef8434581913316a5320d5706",
                        "8861726b360b4d009d450554c6883a3e",
                        "41ea2d62632642aba4db0c54a097b1f5",
                        "468801364a624d4da7a7f3a65d06e7c3",
                        "09f46fe5e4f34985b27212ce26c1a449",
                        "0f014b972e354698acb715ea96235c07",
                        "d0eaf470a3ea4dd28311bf77223e0d9e",
                        "622d4a88cb4e41ea8dc0f8ffc70d9a63",
                        "e81a3dd4c7454e7a838f6a5af2125522",
                        "8fac84f1a8aa4874b908bee2c438606a",
                        "ec1b8d8436f446238b5279604172c7b2",
                        "ab2d5c0d690142da8d30b4639a269da0",
                        "5caa947148114570bb63a798dfa411fd",
                        "58fbaad3abd54f549a59a16040e9a20e",
                        "438337317f084ddab1168a8f21c41a5a",
                        "9bffa38be7d54efe9523f239aa9658ac",
                        "c7474156f5274a2787bdcbfac1612aa8",
                        "2ce0f4402d10428c9d2f490de46c19cb",
                        "45b8f359f4734abc8516c91eedf32520",
                        "3c8e3d62e95647deb29f9264ec691012",
                        "07fa624559cc4019abb7df00c65f5035",
                        "d3aa1863326d4bfaa2b73bca91b4abf6",
                        "efb9dcde922c45f2b461211874934e2c",
                        "a6de6624ffca4033be5a218b758e4eaa",
                        "6ee219eaa4874598b822d16ce08e23cc",
                        "253a02a1155b4307a62705054dfe2b19",
                        "800d0c5a61434fa58b9bb5ffaed60c13",
                        "0283ef3fb63f4c8698d64507c74be86b",
                        "07aa935f553e4647880cc6327ab5f80f",
                        "73cb493d8eb946b4ad3ffcf3a4585040",
                        "53ec134febd24f5bb2e1569bb2c12672",
                        "d30665455f1b4d61843f0870fa200174",
                        "a6964a9cb5ca40f0ba18c3fb234b0cd3",
                        "2ec9934d89394e5daaf43f7b28f5ca2d",
                        "36740ec5cd2540db91134bebb5ea65a5",
                        "ebe8ca40c0df41daa45f69591997d92b",
                        "355175e748624b77ae541b1c27e148d3",
                        "2ee7b1eb10ba4c23a7f1945a8db69e66",
                        "0dbb22d782cb45c3b40b3080dc725379",
                        "0635bc621f1e4d70a14c999e813279f4",
                        "6034afd60b7a42c9a9d8ede422c675e7",
                        "695b09ee3ca04a19846dd10dfdba298b",
                        "65bf5ca6940a47318467476b3e4b737e",
                        "041d1624758f4573afee0bd31232d54b",
                        "4aa2d5e54f9d4a4aa57890ef75b6fcfe",
                        "d78ac0d8f7e347f7b6d710ce7f920020",
                        "d498ef3c7e4849fbaef34b95609b2633",
                        "dbe7bfca33dc496a9f9cb437a6208aa5",
                        "c75afa063a1b407ca7d53b136260dc6d",
                        "ad82ba447d8a498789510118d4c3714d",
                        "bd7b893860934495a0bbef4b77aad87e",
                        "5bcce63ef9db483aa553adcf8d263e74",
                        "cd8df2e9482647d383711f43a9b69580",
                        "f19b00b34c81492dafa83a6a8b24c49f"
                    ]
                },
                "execution": {
                    "iopub.execute_input": "2025-05-11T14:01:40.680940Z",
                    "iopub.status.busy": "2025-05-11T14:01:40.680307Z",
                    "iopub.status.idle": "2025-05-11T14:01:43.312958Z",
                    "shell.execute_reply": "2025-05-11T14:01:43.312238Z",
                    "shell.execute_reply.started": "2025-05-11T14:01:40.680887Z"
                },
                "executionInfo": {
                    "elapsed": 4990,
                    "status": "ok",
                    "timestamp": 1745744227187,
                    "user": {
                        "displayName": "Mostafa Essam",
                        "userId": "04610803808530795661"
                    },
                    "user_tz": -180
                },
                "id": "7aWN8SfXc-na",
                "outputId": "a9fd95dc-975c-4a88-d37b-8846c5235256",
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2b03ebe1d1ea407d870a57f78be85fa4",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "README.md:   0%|          | 0.00/538 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "059c71453ece4f46adadcc88f6426be0",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "train-00000-of-00001.parquet:   0%|          | 0.00/26.7M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6fbff9b860284cf7b4da47cd94ef69d2",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "validation-00000-of-00001.parquet:   0%|          | 0.00/3.36M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "00f7d7a821d548b0b74d6d951b35eeee",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "test-00000-of-00001.parquet:   0%|          | 0.00/6.50M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "ebdc0c81230b43c495d29c6f93d29681",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Generating train split:   0%|          | 0/59320 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "270f135c446a4cfd9e69de7a5e7c58d5",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Generating validation split:   0%|          | 0/7413 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c793aa552a614fbbbafc51d029e336b9",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Generating test split:   0%|          | 0/13057 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "ds = load_dataset(\"hejazizo/mimic-iii\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "execution": {
                    "iopub.execute_input": "2025-05-11T14:01:45.852049Z",
                    "iopub.status.busy": "2025-05-11T14:01:45.851391Z",
                    "iopub.status.idle": "2025-05-11T14:01:45.857276Z",
                    "shell.execute_reply": "2025-05-11T14:01:45.856484Z",
                    "shell.execute_reply.started": "2025-05-11T14:01:45.852028Z"
                },
                "executionInfo": {
                    "elapsed": 8,
                    "status": "ok",
                    "timestamp": 1745744246399,
                    "user": {
                        "displayName": "Mostafa Essam",
                        "userId": "04610803808530795661"
                    },
                    "user_tz": -180
                },
                "id": "TvU2TkLCds0O",
                "outputId": "0588e76b-71b4-4ef6-b458-57d050e0c366",
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "DatasetDict({\n",
                            "    train: Dataset({\n",
                            "        features: ['prompt', 'impressions'],\n",
                            "        num_rows: 59320\n",
                            "    })\n",
                            "    validation: Dataset({\n",
                            "        features: ['prompt', 'impressions'],\n",
                            "        num_rows: 7413\n",
                            "    })\n",
                            "    test: Dataset({\n",
                            "        features: ['prompt', 'impressions'],\n",
                            "        num_rows: 13057\n",
                            "    })\n",
                            "})"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "ds"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T14:02:02.119521Z",
                    "iopub.status.busy": "2025-05-11T14:02:02.118785Z",
                    "iopub.status.idle": "2025-05-11T14:02:02.124437Z",
                    "shell.execute_reply": "2025-05-11T14:02:02.123684Z",
                    "shell.execute_reply.started": "2025-05-11T14:02:02.119493Z"
                },
                "id": "QvWU8VXqdzV0",
                "trusted": true
            },
            "outputs": [],
            "source": [
                "def print_samples(ds, n_samples=1, split='test', shuffle=True, seed=None):\n",
                "    ds = ds[split]\n",
                "    \n",
                "    if shuffle:\n",
                "        ds = ds.shuffle(seed=seed) if seed else ds.shuffle()\n",
                "    \n",
                "    samples = ds.select(range(n_samples))\n",
                "\n",
                "    for i, sample in enumerate(samples):\n",
                "        print(\">> Report:\\n\", textwrap.fill(sample['prompt'], width=100))\n",
                "        print(\"\\n>> Impression:\\n\", textwrap.fill(sample['impressions'], width=100))\n",
                "        if n_samples > 1 and i+1 != n_samples:\n",
                "            print(\"\\n\", \"-\" * 100, \"\\n\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "execution": {
                    "iopub.execute_input": "2025-05-11T14:02:12.264480Z",
                    "iopub.status.busy": "2025-05-11T14:02:12.263632Z",
                    "iopub.status.idle": "2025-05-11T14:02:12.270984Z",
                    "shell.execute_reply": "2025-05-11T14:02:12.270258Z",
                    "shell.execute_reply.started": "2025-05-11T14:02:12.264446Z"
                },
                "executionInfo": {
                    "elapsed": 38,
                    "status": "ok",
                    "timestamp": 1745746451575,
                    "user": {
                        "displayName": "Mostafa Essam",
                        "userId": "04610803808530795661"
                    },
                    "user_tz": -180
                },
                "id": "BpfvQxlOd0Nr",
                "outputId": "ae622f5e-6777-44f3-d9a4-4fe41475e642",
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        ">> Report:\n",
                        " the liver pancreas spleen adrenals and kidneys are normal the aorta is of normal caliber no enlarged\n",
                        "lymph node identified in the retroperitoneum there is bilateral hydronephrosis right side greater\n",
                        "than left\n",
                        "\n",
                        ">> Impression:\n",
                        " 1 bilateral adenxal tumors with resultant bilateral hydronephrosis right side greater than left most\n",
                        "likely metastatic ___\n",
                        "\n",
                        " ---------------------------------------------------------------------------------------------------- \n",
                        "\n",
                        ">> Report:\n",
                        " status post radical hysterectomy there is susceptibility artifact on the left lying between the\n",
                        "bladder and the rectum -- are there surgical clips in this location adjacent to the artifact there\n",
                        "is an ill-defined 16 x 29 mm area of abnormal soft tissue intensity hypointense on t1 with\n",
                        "intermediate intensity on t2 no discrete mass is seen no enlarge pelvic lymph nodes are detected the\n",
                        "bladder wall is not thickened a small amount of free fluid is present within the pelvis there is is\n",
                        "left hydroureter with dilatation of the renal pelvis and prominence of the calyces the hydroureter\n",
                        "extends down to the area of the susceptibility artifact and the adjoining area of abnormal soft\n",
                        "tissue intensity the right renal collecting system is within normal limits comparison was made to ct\n",
                        "dated ___ the area of soft tissue intensity corresponds to some ill-defined stranding seen at that\n",
                        "time however no hydronephrosis was seen on the ___ ct scan\n",
                        "\n",
                        ">> Impression:\n",
                        " 1 due to the patient's previous adverse reaction to gadolinium no contrast was injected 2 there is\n",
                        "ill-defined abnormal soft tissue signal intensity on the left presumably in the region of the recent\n",
                        "surgery nearby susceptibility artifact raises the question of a surgical clip in this location but\n",
                        "could also be secondary to prior transient instrumentation -- clinical correlation requested 3 left\n",
                        "hydroureter and mild hydronephrosis new since ___ ct the transition point lies near the soft tissue\n",
                        "intensity material and susceptibility artifact however due to the artifact it is difficult to\n",
                        "confirm the exact point of transtion in relation to these findings and therefore it could relate to\n",
                        "either finding\n"
                    ]
                }
            ],
            "source": [
                "print_samples(ds, 2, shuffle=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T14:02:58.195794Z",
                    "iopub.status.busy": "2025-05-11T14:02:58.195218Z",
                    "iopub.status.idle": "2025-05-11T14:02:58.199296Z",
                    "shell.execute_reply": "2025-05-11T14:02:58.198654Z",
                    "shell.execute_reply.started": "2025-05-11T14:02:58.195773Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "def add_prefix_fn(example):\n",
                "    return {\n",
                "        \"input\": \"extract: \" + example[\"prompt\"],\n",
                "        \"output\": example[\"impressions\"]\n",
                "    }"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T14:03:06.772072Z",
                    "iopub.status.busy": "2025-05-11T14:03:06.771390Z",
                    "iopub.status.idle": "2025-05-11T14:03:10.078552Z",
                    "shell.execute_reply": "2025-05-11T14:03:10.077706Z",
                    "shell.execute_reply.started": "2025-05-11T14:03:06.772050Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "138c4ed3061f4b9993079a9b9a552652",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Map:   0%|          | 0/59320 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "cf3cf518563a479887c226219354cf9c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Map:   0%|          | 0/7413 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "d1ba1f681a3b4ddd84d157ae163aeb50",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Map:   0%|          | 0/13057 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "ds_prefix = ds.map(\n",
                "    add_prefix_fn,\n",
                "    batched=False,\n",
                "    remove_columns=ds['train'].column_names\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T14:03:12.740039Z",
                    "iopub.status.busy": "2025-05-11T14:03:12.739537Z",
                    "iopub.status.idle": "2025-05-11T14:03:12.744741Z",
                    "shell.execute_reply": "2025-05-11T14:03:12.744031Z",
                    "shell.execute_reply.started": "2025-05-11T14:03:12.740014Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "DatasetDict({\n",
                            "    train: Dataset({\n",
                            "        features: ['input', 'output'],\n",
                            "        num_rows: 59320\n",
                            "    })\n",
                            "    validation: Dataset({\n",
                            "        features: ['input', 'output'],\n",
                            "        num_rows: 7413\n",
                            "    })\n",
                            "    test: Dataset({\n",
                            "        features: ['input', 'output'],\n",
                            "        num_rows: 13057\n",
                            "    })\n",
                            "})"
                        ]
                    },
                    "execution_count": 25,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "ds_prefix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T14:03:24.653668Z",
                    "iopub.status.busy": "2025-05-11T14:03:24.653375Z",
                    "iopub.status.idle": "2025-05-11T14:03:32.478383Z",
                    "shell.execute_reply": "2025-05-11T14:03:32.477587Z",
                    "shell.execute_reply.started": "2025-05-11T14:03:24.653646Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2ead3954305444bb939b27cbcaae1426",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4278ad5587294c26984663c4aa3f48f8",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "5e143d035d8645a5a1be4413cd54ece4",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8fc42dbd073646a6bb9c119f5689c5b6",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "ce322aa1a04244998391338ae985daec",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "74344f5522d644299c4eca5108b1bc04",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "model_checkpoint = \"t5-small\"\n",
                "\n",
                "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
                "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T14:04:07.009067Z",
                    "iopub.status.busy": "2025-05-11T14:04:07.008416Z",
                    "iopub.status.idle": "2025-05-11T14:04:07.013121Z",
                    "shell.execute_reply": "2025-05-11T14:04:07.012394Z",
                    "shell.execute_reply.started": "2025-05-11T14:04:07.009044Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "def tokenize_fn(examples):\n",
                "    model_inputs = tokenizer(\n",
                "        examples[\"input\"],\n",
                "        # padding=\"max_length\",\n",
                "        truncation=True,\n",
                "        max_length=512,\n",
                "    )\n",
                "    \n",
                "    labels = tokenizer(\n",
                "        examples[\"output\"],\n",
                "        # padding=\"max_length\",\n",
                "        truncation=True,\n",
                "        max_length=256,\n",
                "    )\n",
                "\n",
                "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
                "    return model_inputs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T14:04:14.585703Z",
                    "iopub.status.busy": "2025-05-11T14:04:14.585115Z",
                    "iopub.status.idle": "2025-05-11T14:04:43.301672Z",
                    "shell.execute_reply": "2025-05-11T14:04:43.300876Z",
                    "shell.execute_reply.started": "2025-05-11T14:04:14.585677Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "1d6dade69bce42c9b80425b3abd30fc6",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Map:   0%|          | 0/59320 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "0d0ac00054864b7da36ff4cdc789b044",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Map:   0%|          | 0/7413 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "98307b1831ed499aa4c799f7e8944d51",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Map:   0%|          | 0/13057 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "ds_tokenized = ds_prefix.map(\n",
                "    tokenize_fn,\n",
                "    batched=True,\n",
                "    remove_columns=ds_prefix['train'].column_names\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T14:05:02.245326Z",
                    "iopub.status.busy": "2025-05-11T14:05:02.244668Z",
                    "iopub.status.idle": "2025-05-11T14:05:02.249746Z",
                    "shell.execute_reply": "2025-05-11T14:05:02.249133Z",
                    "shell.execute_reply.started": "2025-05-11T14:05:02.245299Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "DatasetDict({\n",
                            "    train: Dataset({\n",
                            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
                            "        num_rows: 59320\n",
                            "    })\n",
                            "    validation: Dataset({\n",
                            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
                            "        num_rows: 7413\n",
                            "    })\n",
                            "    test: Dataset({\n",
                            "        features: ['input_ids', 'attention_mask', 'labels'],\n",
                            "        num_rows: 13057\n",
                            "    })\n",
                            "})"
                        ]
                    },
                    "execution_count": 31,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "ds_tokenized"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "pEKY-LRl1OeP"
            },
            "source": [
                "# Modeling"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T14:56:05.884820Z",
                    "iopub.status.busy": "2025-05-11T14:56:05.883857Z",
                    "iopub.status.idle": "2025-05-11T14:56:05.888883Z",
                    "shell.execute_reply": "2025-05-11T14:56:05.887967Z",
                    "shell.execute_reply.started": "2025-05-11T14:56:05.884789Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "lora_config = LoraConfig(\n",
                "    r=16,\n",
                "    lora_alpha=64,\n",
                "    lora_dropout=0.1,\n",
                "    bias=\"none\",\n",
                "    target_modules=\"all-linear\",\n",
                "    task_type=TaskType.SEQ_2_SEQ_LM\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T14:56:06.292199Z",
                    "iopub.status.busy": "2025-05-11T14:56:06.291640Z",
                    "iopub.status.idle": "2025-05-11T14:56:06.398610Z",
                    "shell.execute_reply": "2025-05-11T14:56:06.397840Z",
                    "shell.execute_reply.started": "2025-05-11T14:56:06.292173Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "model = get_peft_model(\n",
                "    model=model,\n",
                "    peft_config=lora_config\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T14:56:12.149252Z",
                    "iopub.status.busy": "2025-05-11T14:56:12.148983Z",
                    "iopub.status.idle": "2025-05-11T14:56:12.182074Z",
                    "shell.execute_reply": "2025-05-11T14:56:12.181515Z",
                    "shell.execute_reply.started": "2025-05-11T14:56:12.149233Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "training_args = Seq2SeqTrainingArguments(\n",
                "    output_dir=\"./results\",\n",
                "    eval_strategy=\"epoch\",\n",
                "    logging_strategy=\"steps\",\n",
                "    logging_steps=500,\n",
                "    save_strategy=\"epoch\",\n",
                "    save_total_limit=2,\n",
                "    per_device_train_batch_size=16,\n",
                "    per_device_eval_batch_size=16,\n",
                "    # learning_rate=2e-5,\n",
                "    learning_rate = 5e-5,\n",
                "    warmup_steps = 500,  # Optional, helps stabilize early training\n",
                "    weight_decay=0.01,\n",
                "    num_train_epochs=5,\n",
                "    predict_with_generate=True,\n",
                "    fp16=True,\n",
                "    report_to=\"wandb\",\n",
                "    run_name=\"lora-mimic-finetune-v2\",\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T14:56:13.841190Z",
                    "iopub.status.busy": "2025-05-11T14:56:13.840421Z",
                    "iopub.status.idle": "2025-05-11T14:56:13.872533Z",
                    "shell.execute_reply": "2025-05-11T14:56:13.871890Z",
                    "shell.execute_reply.started": "2025-05-11T14:56:13.841167Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "data_collator = DataCollatorForSeq2Seq(\n",
                "    tokenizer=tokenizer,\n",
                "    model=model,\n",
                "    padding=True,\n",
                "    return_tensors='pt'\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T14:56:39.597500Z",
                    "iopub.status.busy": "2025-05-11T14:56:39.597222Z",
                    "iopub.status.idle": "2025-05-11T14:56:39.612683Z",
                    "shell.execute_reply": "2025-05-11T14:56:39.612062Z",
                    "shell.execute_reply.started": "2025-05-11T14:56:39.597480Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/tmp/ipykernel_31/926081374.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
                        "  trainer = Seq2SeqTrainer(\n",
                        "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
                    ]
                }
            ],
            "source": [
                "trainer = Seq2SeqTrainer(\n",
                "    model=model,\n",
                "    tokenizer=tokenizer,\n",
                "    args=training_args,\n",
                "    data_collator=data_collator,\n",
                "    train_dataset=ds_tokenized[\"train\"],\n",
                "    eval_dataset=ds_tokenized[\"validation\"],\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T15:04:10.816716Z",
                    "iopub.status.busy": "2025-05-11T15:04:10.816395Z",
                    "iopub.status.idle": "2025-05-11T18:15:57.394663Z",
                    "shell.execute_reply": "2025-05-11T18:15:57.394135Z",
                    "shell.execute_reply.started": "2025-05-11T15:04:10.816692Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "Tracking run with wandb version 0.19.6"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Run data is saved locally in <code>/kaggle/working/wandb/run-20250511_150411-06mrij3g</code>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Syncing run <strong><a href='https://wandb.ai/mk-mostafaessam-helwan-university/huggingface/runs/06mrij3g' target=\"_blank\">lora-mimic-finetune-v2</a></strong> to <a href='https://wandb.ai/mk-mostafaessam-helwan-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View project at <a href='https://wandb.ai/mk-mostafaessam-helwan-university/huggingface' target=\"_blank\">https://wandb.ai/mk-mostafaessam-helwan-university/huggingface</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View run at <a href='https://wandb.ai/mk-mostafaessam-helwan-university/huggingface/runs/06mrij3g' target=\"_blank\">https://wandb.ai/mk-mostafaessam-helwan-university/huggingface/runs/06mrij3g</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
                        "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "    <div>\n",
                            "      \n",
                            "      <progress value='9270' max='9270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                            "      [9270/9270 3:11:36, Epoch 5/5]\n",
                            "    </div>\n",
                            "    <table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            " <tr style=\"text-align: left;\">\n",
                            "      <th>Epoch</th>\n",
                            "      <th>Training Loss</th>\n",
                            "      <th>Validation Loss</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <td>1</td>\n",
                            "      <td>3.013500</td>\n",
                            "      <td>2.585762</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>2</td>\n",
                            "      <td>2.814000</td>\n",
                            "      <td>2.451436</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>3</td>\n",
                            "      <td>2.716400</td>\n",
                            "      <td>2.376428</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>4</td>\n",
                            "      <td>2.683400</td>\n",
                            "      <td>2.349041</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>5</td>\n",
                            "      <td>2.658200</td>\n",
                            "      <td>2.338226</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table><p>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
                        "  warnings.warn(\n",
                        "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
                        "  warnings.warn(\n",
                        "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
                        "  warnings.warn(\n",
                        "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "TrainOutput(global_step=9270, training_loss=2.859317408359038, metrics={'train_runtime': 11506.1271, 'train_samples_per_second': 25.778, 'train_steps_per_second': 0.806, 'total_flos': 3.617155392838042e+16, 'train_loss': 2.859317408359038, 'epoch': 5.0})"
                        ]
                    },
                    "execution_count": 45,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "trainer.train()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Charts and Plots: https://wandb.ai/mk-mostafaessam-helwan-university/huggingface?nw=nwusermkmostafaessam"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Testing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T18:33:51.588819Z",
                    "iopub.status.busy": "2025-05-11T18:33:51.588128Z",
                    "iopub.status.idle": "2025-05-11T18:33:51.596502Z",
                    "shell.execute_reply": "2025-05-11T18:33:51.595756Z",
                    "shell.execute_reply.started": "2025-05-11T18:33:51.588794Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        ">> Report: extract: the liver pancreas spleen adrenals and kidneys are normal the aorta is of normal caliber no enlarged lymph node identified in the retroperitoneum there is bilateral hydronephrosis right side greater than left \n",
                        "\n",
                        "\n",
                        ">> Impression: 1 bilateral adenxal tumors with resultant bilateral hydronephrosis right side greater than left most likely metastatic ___\n"
                    ]
                }
            ],
            "source": [
                "ex = ds_prefix['test'][0]\n",
                "\n",
                "print(\">> Report:\", ex['input'], '\\n\\n')\n",
                "print(\">> Impression:\", ex['output'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T18:33:59.135641Z",
                    "iopub.status.busy": "2025-05-11T18:33:59.134995Z",
                    "iopub.status.idle": "2025-05-11T18:33:59.147615Z",
                    "shell.execute_reply": "2025-05-11T18:33:59.147057Z",
                    "shell.execute_reply.started": "2025-05-11T18:33:59.135618Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'input_ids': tensor([[ 5819,    10,     8, 11501,  2131,  5045,     9,     7,     3,     7,\n",
                            "          4788,    35, 23563,     7,    11, 11546,     7,    33,  1389,     8,\n",
                            "             3,     9,   127,    17,     9,    19,    13,  1389,   212, 10661,\n",
                            "           150,     3, 30670, 25049,   150,   221,  4313,    16,     8,  9337,\n",
                            "          4267,  6948,   440,   132,    19, 24097,  7668,    29,    15, 31156,\n",
                            "             7,   159,   269,   596,  2123,   145,   646,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
                            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
                            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
                        ]
                    },
                    "execution_count": 47,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "inputs = tokenizer(ex['input'], return_tensors='pt')#.to(model.device)\n",
                "inputs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T18:34:01.549273Z",
                    "iopub.status.busy": "2025-05-11T18:34:01.549015Z",
                    "iopub.status.idle": "2025-05-11T18:34:01.556054Z",
                    "shell.execute_reply": "2025-05-11T18:34:01.555216Z",
                    "shell.execute_reply.started": "2025-05-11T18:34:01.549252Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'cuda'"
                        ]
                    },
                    "execution_count": 48,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "device"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T18:34:03.130001Z",
                    "iopub.status.busy": "2025-05-11T18:34:03.129656Z",
                    "iopub.status.idle": "2025-05-11T18:34:03.144334Z",
                    "shell.execute_reply": "2025-05-11T18:34:03.143617Z",
                    "shell.execute_reply.started": "2025-05-11T18:34:03.129975Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'input_ids': tensor([[ 5819,    10,     8, 11501,  2131,  5045,     9,     7,     3,     7,\n",
                            "          4788,    35, 23563,     7,    11, 11546,     7,    33,  1389,     8,\n",
                            "             3,     9,   127,    17,     9,    19,    13,  1389,   212, 10661,\n",
                            "           150,     3, 30670, 25049,   150,   221,  4313,    16,     8,  9337,\n",
                            "          4267,  6948,   440,   132,    19, 24097,  7668,    29,    15, 31156,\n",
                            "             7,   159,   269,   596,  2123,   145,   646,     1]],\n",
                            "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
                            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
                            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
                        ]
                    },
                    "execution_count": 49,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "inputs = inputs.to(device)\n",
                "inputs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T18:34:05.521634Z",
                    "iopub.status.busy": "2025-05-11T18:34:05.520975Z",
                    "iopub.status.idle": "2025-05-11T18:34:05.990318Z",
                    "shell.execute_reply": "2025-05-11T18:34:05.989469Z",
                    "shell.execute_reply.started": "2025-05-11T18:34:05.521600Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "tensor([[    0,   209, 24097,  7668,    29,    15, 31156,     7,   159,   269,\n",
                            "           596,  2123,   145,   646,     1]], device='cuda:0')"
                        ]
                    },
                    "execution_count": 50,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "outputs = model.generate(**inputs, max_new_tokens=200)\n",
                "outputs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T18:34:12.241680Z",
                    "iopub.status.busy": "2025-05-11T18:34:12.241400Z",
                    "iopub.status.idle": "2025-05-11T18:34:12.247676Z",
                    "shell.execute_reply": "2025-05-11T18:34:12.247091Z",
                    "shell.execute_reply.started": "2025-05-11T18:34:12.241661Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'1 bilateral hydronephrosis right side greater than left'"
                        ]
                    },
                    "execution_count": 51,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "tokenizer.decode(outputs[0], skip_special_tokens=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 77,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T19:20:42.805600Z",
                    "iopub.status.busy": "2025-05-11T19:20:42.805356Z",
                    "iopub.status.idle": "2025-05-11T19:20:42.812692Z",
                    "shell.execute_reply": "2025-05-11T19:20:42.812078Z",
                    "shell.execute_reply.started": "2025-05-11T19:20:42.805584Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "from torch.utils.data import DataLoader\n",
                "\n",
                "def get_yt_yp(model):\n",
                "    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
                "    \n",
                "    dataloader = DataLoader(\n",
                "        ds_tokenized[\"test\"].shuffle().select(range(1000)),\n",
                "        batch_size=8,\n",
                "        collate_fn=data_collator\n",
                "    )\n",
                "    \n",
                "    model.eval()\n",
                "    predictions = []\n",
                "    references = []\n",
                "    \n",
                "    for batch in tqdm(dataloader):\n",
                "        input_ids = batch[\"input_ids\"].to(model.device)\n",
                "        attention_mask = batch[\"attention_mask\"].to(model.device)\n",
                "        labels = batch[\"labels\"]\n",
                "    \n",
                "        with torch.no_grad():\n",
                "            outputs = model.generate(\n",
                "                input_ids=input_ids,\n",
                "                attention_mask=attention_mask,\n",
                "                max_new_tokens=128\n",
                "            )\n",
                "    \n",
                "        decoded_preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
                "        \n",
                "        labels = labels.clone()\n",
                "        labels[labels == -100] = tokenizer.pad_token_id\n",
                "        decoded_refs = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
                "    \n",
                "        predictions.extend(decoded_preds)\n",
                "        references.extend(decoded_refs)\n",
                "        \n",
                "        return references, predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "references, predictions = get_yt_yp(model)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-04-30T17:28:56.724832Z",
                    "iopub.status.busy": "2025-04-30T17:28:56.724140Z",
                    "iopub.status.idle": "2025-04-30T17:28:56.727799Z",
                    "shell.execute_reply": "2025-04-30T17:28:56.727237Z",
                    "shell.execute_reply.started": "2025-04-30T17:28:56.724807Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# !pip install rouge_score"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T18:38:52.999295Z",
                    "iopub.status.busy": "2025-05-11T18:38:52.998523Z",
                    "iopub.status.idle": "2025-05-11T18:38:55.267205Z",
                    "shell.execute_reply": "2025-05-11T18:38:55.266590Z",
                    "shell.execute_reply.started": "2025-05-11T18:38:52.999266Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4ceb8fd3725f48be83caf163334df6a7",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/plain": [
                            "{'rouge1': 0.3232767395492883,\n",
                            " 'rouge2': 0.14866990456747228,\n",
                            " 'rougeL': 0.25468425796453587,\n",
                            " 'rougeLsum': 0.25502170521003165}"
                        ]
                    },
                    "execution_count": 53,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import evaluate\n",
                "\n",
                "rouge = evaluate.load(\"rouge\")  # Recall-Oriented Understudy for Gisting Evaluation\n",
                "\n",
                "results = rouge.compute(\n",
                "    predictions=predictions,\n",
                "    references=references\n",
                ")\n",
                "\n",
                "results"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 📝 ROUGE Evaluation Report\n",
                "\n",
                "---\n",
                "\n",
                "#### 🔍 What These Scores Mean:\n",
                "\n",
                "- **ROUGE-1 (32.3%)**: Measures **unigram (word-level)** overlap. Decent for basic content similarity.\n",
                "- **ROUGE-2 (14.8%)**: Measures **bigram** overlap. Lower, indicating less fluency or coherence.\n",
                "- **ROUGE-L / ROUGE-Lsum (~25.5%)**: Measures the **longest common subsequence** — good for capturing sentence-level structure.\n",
                "\n",
                "---\n",
                "\n",
                "#### 🎯 Interpretation:\n",
                "\n",
                "**If your task is something like:**\n",
                "\n",
                "- **Feature Extraction**:  \n",
                "  These scores are **in the typical range** for early or base models  \n",
                "  _(e.g., many feature extraction baselines score ~0.2–0.4 ROUGE-1 on CNN/DailyMail)_.\n",
                "\n",
                "- **Radiology Report Generation / Medical Domain**:  \n",
                "  These scores are actually **quite reasonable**, because:\n",
                "  - Medical text uses **domain-specific vocabulary**.\n",
                "  - There are often **multiple valid ways to phrase** the same content.\n",
                "  - **ROUGE** often **underrepresents semantic quality** in such contexts.\n",
                "\n",
                "---\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T18:45:34.090808Z",
                    "iopub.status.busy": "2025-05-11T18:45:34.090532Z",
                    "iopub.status.idle": "2025-05-11T18:45:35.527635Z",
                    "shell.execute_reply": "2025-05-11T18:45:35.526950Z",
                    "shell.execute_reply.started": "2025-05-11T18:45:34.090788Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "28c9e2d94a654b53979f132800ac9517",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "005fe48b72374300893c235d52313a69",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "7ed56f243eba4ff89b106a582ca82c38",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/plain": [
                            "{'bleu': 0.08188674223759468,\n",
                            " 'precisions': [0.3962468749058707,\n",
                            "  0.17068853069971118,\n",
                            "  0.09378505721337223,\n",
                            "  0.05470198675496689],\n",
                            " 'brevity_penalty': 0.5999801181053808,\n",
                            " 'length_ratio': 0.6618752367471441,\n",
                            " 'translation_length': 33199,\n",
                            " 'reference_length': 50159}"
                        ]
                    },
                    "execution_count": 55,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import evaluate\n",
                "\n",
                "rouge = evaluate.load(\"bleu\")  # Bilingual Evaluation Understudy\n",
                "\n",
                "results = rouge.compute(\n",
                "    predictions=predictions,\n",
                "    references=references\n",
                ")\n",
                "\n",
                "results"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 📝 BLEU Evaluation Report\n",
                "\n",
                "---\n",
                "\n",
                "#### 📊 BLEU Score Summary:\n",
                "\n",
                "- **BLEU Score**: **8.2%**\n",
                "- **Precisions**:\n",
                "  - 1-gram: **39.6%**\n",
                "  - 2-gram: **17.1%**\n",
                "  - 3-gram: **9.4%**\n",
                "  - 4-gram: **5.5%**\n",
                "- **Brevity Penalty**: **0.59**\n",
                "- **Length Ratio**: **0.66**\n",
                "  - Translation Length: **33,199**\n",
                "  - Reference Length: **50,159**\n",
                "\n",
                "---\n",
                "\n",
                "#### 🔍 What These Scores Mean:\n",
                "\n",
                "- **Low BLEU (~8%)**: Indicates **limited n-gram overlap** with references.\n",
                "- **High 1-gram precision**: Shows the model captures **basic words** well.\n",
                "- **Steep drop in higher n-grams**: Suggests difficulty in **generating fluent multi-word phrases** or full sentence structures.\n",
                "- **High brevity penalty**: Model is **generating shorter outputs** than expected.\n",
                "\n",
                "---\n",
                "\n",
                "#### 🎯 Interpretation:\n",
                "\n",
                "- For **radiology report generation**, low BLEU is not uncommon:\n",
                "  - Multiple valid phrasings exist for the same findings.\n",
                "  - BLEU is known to **undervalue semantic correctness** and **clinical acceptability**.\n",
                "  - Consider complementing BLEU with **ROUGE**, **BERTScore**, or even **human evaluation**.\n",
                "\n",
                "---\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 90,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T19:24:41.542209Z",
                    "iopub.status.busy": "2025-05-11T19:24:41.541945Z",
                    "iopub.status.idle": "2025-05-11T19:24:41.734737Z",
                    "shell.execute_reply": "2025-05-11T19:24:41.734207Z",
                    "shell.execute_reply.started": "2025-05-11T19:24:41.542190Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 85,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T19:23:57.325759Z",
                    "iopub.status.busy": "2025-05-11T19:23:57.325200Z",
                    "iopub.status.idle": "2025-05-11T19:24:02.879891Z",
                    "shell.execute_reply": "2025-05-11T19:24:02.879171Z",
                    "shell.execute_reply.started": "2025-05-11T19:23:57.325736Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/125 [00:05<?, ?it/s]\n"
                    ]
                }
            ],
            "source": [
                "references, predictions = get_yt_yp(model=base_model)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 86,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T19:24:06.817327Z",
                    "iopub.status.busy": "2025-05-11T19:24:06.816867Z",
                    "iopub.status.idle": "2025-05-11T19:24:07.250428Z",
                    "shell.execute_reply": "2025-05-11T19:24:07.249807Z",
                    "shell.execute_reply.started": "2025-05-11T19:24:06.817304Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'rouge1': 0.249474221222722,\n",
                            " 'rouge2': 0.11572933593748251,\n",
                            " 'rougeL': 0.18151281294084895,\n",
                            " 'rougeLsum': 0.18215509159755788}"
                        ]
                    },
                    "execution_count": 86,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import evaluate\n",
                "\n",
                "rouge = evaluate.load(\"rouge\")  # Recall-Oriented Understudy for Gisting Evaluation\n",
                "\n",
                "results = rouge.compute(\n",
                "    predictions=predictions,\n",
                "    references=references\n",
                ")\n",
                "\n",
                "results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 87,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T19:24:08.513667Z",
                    "iopub.status.busy": "2025-05-11T19:24:08.513376Z",
                    "iopub.status.idle": "2025-05-11T19:24:09.007586Z",
                    "shell.execute_reply": "2025-05-11T19:24:09.007025Z",
                    "shell.execute_reply.started": "2025-05-11T19:24:08.513637Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'bleu': 0.10307073594914497,\n",
                            " 'precisions': [0.24110671936758893,\n",
                            "  0.12449799196787148,\n",
                            "  0.07551020408163266,\n",
                            "  0.04979253112033195],\n",
                            " 'brevity_penalty': 1.0,\n",
                            " 'length_ratio': 1.3863013698630138,\n",
                            " 'translation_length': 506,\n",
                            " 'reference_length': 365}"
                        ]
                    },
                    "execution_count": 87,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import evaluate\n",
                "\n",
                "rouge = evaluate.load(\"bleu\")  # Bilingual Evaluation Understudy\n",
                "\n",
                "results = rouge.compute(\n",
                "    predictions=predictions,\n",
                "    references=references\n",
                ")\n",
                "\n",
                "results"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Saving the model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T18:48:03.327810Z",
                    "iopub.status.busy": "2025-05-11T18:48:03.327098Z",
                    "iopub.status.idle": "2025-05-11T18:48:03.628830Z",
                    "shell.execute_reply": "2025-05-11T18:48:03.628140Z",
                    "shell.execute_reply.started": "2025-05-11T18:48:03.327786Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "model.save_pretrained(save_directory='lora_adapter_only')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T18:48:31.271547Z",
                    "iopub.status.busy": "2025-05-11T18:48:31.270796Z",
                    "iopub.status.idle": "2025-05-11T18:48:32.207297Z",
                    "shell.execute_reply": "2025-05-11T18:48:32.206748Z",
                    "shell.execute_reply.started": "2025-05-11T18:48:31.271521Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
                "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
                "peft_model = PeftModel.from_pretrained(model=base_model, model_id=\"/kaggle/working/lora_adapter_only\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T18:49:29.215263Z",
                    "iopub.status.busy": "2025-05-11T18:49:29.214642Z",
                    "iopub.status.idle": "2025-05-11T18:49:31.140506Z",
                    "shell.execute_reply": "2025-05-11T18:49:31.139971Z",
                    "shell.execute_reply.started": "2025-05-11T18:49:29.215238Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "07b194081ac04af9adb08e1575d871d7",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "adapter_model.safetensors:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/plain": [
                            "CommitInfo(commit_url='https://huggingface.co/MK-Mostafa/t5-small-mimic-lora-finetune-v1/commit/781c63fbcfc92e6d3da04688c41f9cee023d7838', commit_message='Upload model', commit_description='', oid='781c63fbcfc92e6d3da04688c41f9cee023d7838', pr_url=None, repo_url=RepoUrl('https://huggingface.co/MK-Mostafa/t5-small-mimic-lora-finetune-v1', endpoint='https://huggingface.co', repo_type='model', repo_id='MK-Mostafa/t5-small-mimic-lora-finetune-v1'), pr_revision=None, pr_num=None)"
                        ]
                    },
                    "execution_count": 58,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "peft_model.push_to_hub(\"MK-Mostafa/t5-small-mimic-lora-finetune-v1\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T18:49:42.747620Z",
                    "iopub.status.busy": "2025-05-11T18:49:42.747159Z",
                    "iopub.status.idle": "2025-05-11T18:49:44.710082Z",
                    "shell.execute_reply": "2025-05-11T18:49:44.709478Z",
                    "shell.execute_reply.started": "2025-05-11T18:49:42.747597Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6fafd0af610e46dab9290e587887bbf1",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "d18e44c9398045afbe2d3cddce68ed3a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/plain": [
                            "CommitInfo(commit_url='https://huggingface.co/MK-Mostafa/t5-small-mimic-lora-finetune-v1/commit/89a112db242b4e3ec045ee1de9317e73ac9de436', commit_message='Upload tokenizer', commit_description='', oid='89a112db242b4e3ec045ee1de9317e73ac9de436', pr_url=None, repo_url=RepoUrl('https://huggingface.co/MK-Mostafa/t5-small-mimic-lora-finetune-v1', endpoint='https://huggingface.co', repo_type='model', repo_id='MK-Mostafa/t5-small-mimic-lora-finetune-v1'), pr_revision=None, pr_num=None)"
                        ]
                    },
                    "execution_count": 59,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "tokenizer.push_to_hub(\"MK-Mostafa/t5-small-mimic-lora-finetune-v1\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T18:49:55.376153Z",
                    "iopub.status.busy": "2025-05-11T18:49:55.375613Z",
                    "iopub.status.idle": "2025-05-11T18:50:05.974453Z",
                    "shell.execute_reply": "2025-05-11T18:50:05.973730Z",
                    "shell.execute_reply.started": "2025-05-11T18:49:55.376129Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "1963552ee83640fba63982166bec6f8b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "model.safetensors:   0%|          | 0.00/251M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/plain": [
                            "CommitInfo(commit_url='https://huggingface.co/MK-Mostafa/t5-small-mimic-lora-finetune-v1/commit/d79cf8ad3be061566395605e76ca96ecf6573ffa', commit_message='Upload T5ForConditionalGeneration', commit_description='', oid='d79cf8ad3be061566395605e76ca96ecf6573ffa', pr_url=None, repo_url=RepoUrl('https://huggingface.co/MK-Mostafa/t5-small-mimic-lora-finetune-v1', endpoint='https://huggingface.co', repo_type='model', repo_id='MK-Mostafa/t5-small-mimic-lora-finetune-v1'), pr_revision=None, pr_num=None)"
                        ]
                    },
                    "execution_count": 60,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "base_model.push_to_hub(\"MK-Mostafa/t5-small-mimic-lora-finetune-v1\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Inference"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T18:50:08.374150Z",
                    "iopub.status.busy": "2025-05-11T18:50:08.373673Z",
                    "iopub.status.idle": "2025-05-11T18:50:08.379176Z",
                    "shell.execute_reply": "2025-05-11T18:50:08.378497Z",
                    "shell.execute_reply.started": "2025-05-11T18:50:08.374127Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
                "from peft import PeftModel\n",
                "import torch"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 62,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T18:50:14.310083Z",
                    "iopub.status.busy": "2025-05-11T18:50:14.309629Z",
                    "iopub.status.idle": "2025-05-11T18:50:16.994178Z",
                    "shell.execute_reply": "2025-05-11T18:50:16.993395Z",
                    "shell.execute_reply.started": "2025-05-11T18:50:14.310060Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "ec6f83175ea144b08c2af87420d989bc",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "tokenizer_config.json:   0%|          | 0.00/20.8k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "874590026ec24db9b2cde8ff1373c3bf",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "32ba09b866ee4704b64f52b727fcf316",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "92afa26e944a43dead0abe6ceb92fafc",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "special_tokens_map.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "acc3765c2180487ca8c95c8499f317dd",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "83822f20c6af4e68853d4c1bc1e7bb62",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "adapter_config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e6ae38a49d3e430ba1a8f5eb22f8a40f",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "adapter_model.safetensors:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "tokenizer = AutoTokenizer.from_pretrained(\"MK-Mostafa/t5-small-mimic-lora-finetune-v1\")\n",
                "base_model = AutoModelForSeq2SeqLM.from_pretrained(\"MK-Mostafa/t5-small-mimic-lora-finetune-v1\")\n",
                "model = PeftModel.from_pretrained(base_model, \"MK-Mostafa/t5-small-mimic-lora-finetune-v1\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 63,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T18:50:21.938773Z",
                    "iopub.status.busy": "2025-05-11T18:50:21.938022Z",
                    "iopub.status.idle": "2025-05-11T18:50:21.945203Z",
                    "shell.execute_reply": "2025-05-11T18:50:21.944410Z",
                    "shell.execute_reply.started": "2025-05-11T18:50:21.938741Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "device(type='cuda')"
                        ]
                    },
                    "execution_count": 63,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "device"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 96,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T19:28:13.739938Z",
                    "iopub.status.busy": "2025-05-11T19:28:13.739622Z",
                    "iopub.status.idle": "2025-05-11T19:28:13.903616Z",
                    "shell.execute_reply": "2025-05-11T19:28:13.902979Z",
                    "shell.execute_reply.started": "2025-05-11T19:28:13.739890Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "cuda:0\n"
                    ]
                }
            ],
            "source": [
                "base_model = base_model.to(device)\n",
                "base_model.eval()\n",
                "\n",
                "model = model.to(device)\n",
                "model.eval()\n",
                "\n",
                "print( model.device )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T18:51:20.693849Z",
                    "iopub.status.busy": "2025-05-11T18:51:20.693553Z",
                    "iopub.status.idle": "2025-05-11T18:51:21.279698Z",
                    "shell.execute_reply": "2025-05-11T18:51:21.279144Z",
                    "shell.execute_reply.started": "2025-05-11T18:51:20.693829Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'1 no evidence of a stranding or hydronephrosis 2 ill-defined stranding on the left lying between the bladder and the rectum'"
                        ]
                    },
                    "execution_count": 70,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "inputs = tokenizer(ds_prefix['test'][1]['input'], return_tensors=\"pt\")\n",
                "inputs = inputs.to(device)\n",
                "\n",
                "outputs = model.generate(**inputs, max_new_tokens=200)\n",
                "\n",
                "tokenizer.decode(outputs[0], skip_special_tokens=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 91,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T19:27:10.293954Z",
                    "iopub.status.busy": "2025-05-11T19:27:10.293620Z",
                    "iopub.status.idle": "2025-05-11T19:27:10.299837Z",
                    "shell.execute_reply": "2025-05-11T19:27:10.299293Z",
                    "shell.execute_reply.started": "2025-05-11T19:27:10.293905Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "def generate_output(report, model, max_new_tokens=200):\n",
                "    report = \"extract: \" + report\n",
                "    inputs = tokenizer(\n",
                "        report,\n",
                "        padding=False,\n",
                "        truncation=True,\n",
                "        max_length=512,\n",
                "        return_tensors=\"pt\"\n",
                "    )\n",
                "\n",
                "    inputs = inputs.to(device)\n",
                "    \n",
                "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
                "    \n",
                "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
                "    \n",
                "    return generated_text"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 92,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T19:27:11.983044Z",
                    "iopub.status.busy": "2025-05-11T19:27:11.982266Z",
                    "iopub.status.idle": "2025-05-11T19:27:11.989150Z",
                    "shell.execute_reply": "2025-05-11T19:27:11.988489Z",
                    "shell.execute_reply.started": "2025-05-11T19:27:11.983012Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'status post radical hysterectomy there is susceptibility artifact on the left lying between the bladder and the rectum -- are there surgical clips in this location adjacent to the artifact there is an ill-defined 16 x 29 mm area of abnormal soft tissue intensity hypointense on t1 with intermediate intensity on t2 no discrete mass is seen no enlarge pelvic lymph nodes are detected the bladder wall is not thickened a small amount of free fluid is present within the pelvis there is is left hydroureter with dilatation of the renal pelvis and prominence of the calyces the hydroureter extends down to the area of the susceptibility artifact and the adjoining area of abnormal soft tissue intensity the right renal collecting system is within normal limits comparison was made to ct dated ___ the area of soft tissue intensity corresponds to some ill-defined stranding seen at that time however no hydronephrosis was seen on the ___ ct scan'"
                        ]
                    },
                    "execution_count": 92,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "ds['test'][1]['prompt']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 98,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T19:28:35.422892Z",
                    "iopub.status.busy": "2025-05-11T19:28:35.422605Z",
                    "iopub.status.idle": "2025-05-11T19:28:36.591467Z",
                    "shell.execute_reply": "2025-05-11T19:28:36.590693Z",
                    "shell.execute_reply.started": "2025-05-11T19:28:35.422871Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "': status post radical hysterectomy there is susceptibility artifact on the left lying between the bladder and the rectum -- are there surgical clips adjacent to the artifact there is an ill-defined 16 x 29 mm area of abnormal soft tissue intensity hypointense on t1 with intermediate intensity on t2 no discrete mass is seen no enlarge pelvic lymph nodes are detected the bladder wall is not thickened a small amount of free fluid is present within the pelvis there'"
                        ]
                    },
                    "execution_count": 98,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "generate_output(\"\"\"\n",
                "    status post radical hysterectomy there is susceptibility artifact on the left lying between\n",
                "    the bladder and the rectum -- are there surgical clips in this location adjacent to the\n",
                "    artifact there is an ill-defined 16 x 29 mm area of abnormal soft tissue intensity\n",
                "    hypointense on t1 with intermediate intensity on t2 no discrete mass is seen no enlarge\n",
                "    pelvic lymph nodes are detected the bladder wall is not thickened a small amount of free\n",
                "    fluid is present within the pelvis there is is left hydroureter with dilatation of the renal\n",
                "    pelvis and prominence of the calyces the hydroureter extends down to the area of the\n",
                "    susceptibility artifact and the adjoining area of abnormal soft tissue intensity the right\n",
                "    renal collecting system is within normal limits comparison was made to ct dated ___ the area\n",
                "    of soft tissue intensity corresponds to some ill-defined stranding seen at that time however\n",
                "    no hydronephrosis was seen on the ___ ct scan\n",
                "\"\"\",\n",
                "    model=base_model\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 93,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-05-11T19:27:12.821440Z",
                    "iopub.status.busy": "2025-05-11T19:27:12.821031Z",
                    "iopub.status.idle": "2025-05-11T19:27:13.430399Z",
                    "shell.execute_reply": "2025-05-11T19:27:13.429697Z",
                    "shell.execute_reply.started": "2025-05-11T19:27:12.821420Z"
                },
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'1 no evidence of a stranding or hydronephrosis 2 ill-defined stranding on the left lying between the bladder and the rectum'"
                        ]
                    },
                    "execution_count": 93,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "generate_output(\"\"\"\n",
                "    status post radical hysterectomy there is susceptibility artifact on the left lying between\n",
                "    the bladder and the rectum -- are there surgical clips in this location adjacent to the\n",
                "    artifact there is an ill-defined 16 x 29 mm area of abnormal soft tissue intensity\n",
                "    hypointense on t1 with intermediate intensity on t2 no discrete mass is seen no enlarge\n",
                "    pelvic lymph nodes are detected the bladder wall is not thickened a small amount of free\n",
                "    fluid is present within the pelvis there is is left hydroureter with dilatation of the renal\n",
                "    pelvis and prominence of the calyces the hydroureter extends down to the area of the\n",
                "    susceptibility artifact and the adjoining area of abnormal soft tissue intensity the right\n",
                "    renal collecting system is within normal limits comparison was made to ct dated ___ the area\n",
                "    of soft tissue intensity corresponds to some ill-defined stranding seen at that time however\n",
                "    no hydronephrosis was seen on the ___ ct scan\n",
                "\"\"\",\n",
                "    model=model\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "colab": {
            "authorship_tag": "ABX9TyMwWUsVP/LYZLHodaJDYoIE",
            "provenance": []
        },
        "kaggle": {
            "accelerator": "nvidiaTeslaT4",
            "dataSources": [],
            "dockerImageVersionId": 31011,
            "isGpuEnabled": true,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
